---
license: mit
base_model:
  - FacebookAI/xlm-roberta-large
language:
  - ru
tags:
  - Reasoning
  - Logical-Analysis
  - Text-Classification
  - AI-Safety
  - Evaluation
  - Judge-model
  - Argumentation
---

[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-model-blue)](https://huggingface.co/skatzR/RQA-X1.1)

# ğŸ§  RQA â€” Reasoning Quality Analyzer (R1)

**RQA** is a **judge model** designed to evaluate the *quality of reasoning in text*.  
It does **not** generate, rewrite, or explain content â€” instead, it **assesses whether a text contains logical problems**, and if so, **what kind**.

> **RQA is a judge, not a teacher and not a generator.**

---

## ğŸ” What Problem Does RQA Solve?

Texts written by humans or LLMs can:

- sound coherent,
- use correct vocabulary,
- appear persuasive,

â€¦but still contain **logical problems** that are:

- implicit,
- structural,
- hidden in argumentation.

**RQA focuses strictly on reasoning quality**, not on style, sentiment, or factual correctness.

---

## ğŸ§© Model Overview

| Property | Value |
|--------|------|
| **Model Type** | Judge / Evaluator |
| **Base Encoder** | [XLM-RoBERTa Large](https://huggingface.co/FacebookAI/xlm-roberta-large) |
| **Pooling** | Mean pooling |
| **Heads** | 2 (binary + multi-label) |
| **Language** | Russian ğŸ‡·ğŸ‡º |
| **License** | MIT |

---

## ğŸ§  What the Model Predicts

RQA produces **two independent signals** that are combined at inference time:

### 1ï¸âƒ£ Logical Issue Detection (Binary)

- `has_issue âˆˆ {false, true}`
- Calibrated probability available
- Designed to answer:  
  **â€œDoes this text contain a reasoning problem?â€**

### 2ï¸âƒ£ Error Type Signals (Multi-label)

The model estimates probabilities for specific error types:

- `false_causality`
- `unsupported_claim`
- `overgeneralization`
- `missing_premise`
- `contradiction`
- `circular_reasoning`

âš ï¸ **Important**  
Error type probabilities are **diagnostic signals**, not mandatory labels.  
They are surfaced **only if `has_issue == true`** during inference.

---

## ğŸŸ¡ Hidden Logical Problems (Key Concept)

RQA explicitly distinguishes between:

### ğŸ”´ Explicit Logical Errors
Clearly identifiable fallacies:
- invalid causal inference
- circular reasoning
- contradictions
- unsupported claims

### ğŸŸ¡ Hidden Logical Problems
Texts that are:
- argumentative or persuasive,
- structurally incomplete,
- reliant on implicit assumptions,

but **do not contain a cleanly classifiable fallacy**.

Examples:
- missing or unstated premises
- rhetorical generalizations
- context-dependent claims

Hidden problems are **not misclassifications** â€”  
they are an **intended diagnostic category**.

---

## âš–ï¸ Inference Logic (Important)

The model uses **decision logic on top of raw logits**:

- Binary head decides **whether a problem exists**
- Error heads provide **type-level evidence**
- If:
  - `has_issue == false`
  - but error probabilities are non-zero  
  â†’ the text may be flagged as **borderline** or **hidden problem**

This prevents:
- false positive error labels,
- incoherent outputs,
- over-triggering on clean factual texts.

---

## ğŸ—ï¸ Architecture Details

- **Encoder**: XLM-RoBERTa Large (pretrained weights preserved)
- **Pooling**: Mean pooling (robust for long texts)
- **Two independent projections**:
  - binary reasoning head
  - multi-label error head
- Separate dropout and projections to reduce negative transfer

---

## ğŸ“ Training Philosophy

### ğŸ”’ Strict Data Contract

- Logical texts **contain no errors**
- Hidden-problem texts **contain no explicit fallacies**
- Invalid samples are **removed**, not auto-corrected

### âš–ï¸ Balanced Difficulty

- Hidden problems â‰¤ **30%** of problematic texts
- Prevents collapse into vague uncertainty detection

### ğŸ¯ Loss Design

- Binary BCE for issue detection
- Masked multi-label loss for error types
- Stability-oriented multi-task optimization

---

## ğŸŒ¡ï¸ Confidence Calibration

RQA applies **post-hoc temperature scaling**:

- Separate calibration for:
  - `has_issue`
  - each error type
- Enables:
  - meaningful probabilities
  - safe threshold tuning
  - production use without retraining

---

## ğŸš€ Intended Use

### âœ… Recommended for:

- Reasoning quality evaluation
- LLM output auditing
- AI safety pipelines
- Argumentation analysis
- Pre-filtering / routing systems

### âŒ Not intended for:

- Text generation
- Error correction
- Explanation or tutoring
- Grammar or style analysis
- Fact checking

---

## ğŸ§ª Model Behavior

- Conservative by design
- Optimized for **low false positives**
- Explicitly robust to:
  - topic changes
  - writing style
  - emotional tone

RQA judges **logical structure**, not persuasion quality.

---

## ğŸ“š Training Data (High-level)

- **Custom-built dataset**
- **Thousands of long-form argumentative texts**
- **Multiple domains and reasoning styles**
- Carefully controlled balance of:
  - logical texts
  - explicit errors
  - hidden problems

> The dataset was designed specifically for **judge behavior**, not for text generation.

---

## âš ï¸ Limitations

- Logical validity â‰  factual correctness
- Purely descriptive texts may still trigger *diagnostic signals*
- Highly rhetorical or persuasive texts can be flagged as **hidden problems**
- Philosophical disagreement is **not always** a logical error

---

## ğŸ§© Philosophy

> **Good reasoning is not about sounding convincing â€”  
> it is about what actually follows from what.**

RQA is built around this principle.

---

## ğŸ”§ Implementation Details

- Custom Hugging Face architecture (`modeling_rqa.py`)
- Requires:
  - `trust_remote_code=True`
- Uses `safetensors`
- No `.bin` weights (this is expected behavior)

---

## ğŸš€ Quick Start

```python
import torch
from transformers import AutoTokenizer, AutoModel

device = "cuda" if torch.cuda.is_available() else "cpu"

tokenizer = AutoTokenizer.from_pretrained(
    "skatzR/RQA-R1",
    trust_remote_code=True
)

model = AutoModel.from_pretrained(
    "skatzR/RQA-R1",
    trust_remote_code=True
).to(device)

model.eval()

```
---

## ğŸ§  Reference Inference Logic

RQA is designed to be used with **explicit post-processing logic**, including:

- temperature scaling
- thresholding
- disagreement diagnostics
- hidden-problem detection

A **fully working reference implementation** is provided here:


ğŸ‘‰ **[ğŸ“„ inference.py](https://huggingface.co/skatzR/RQA-X1.1/blob/main/inference.py) â€” Reference Inference Implementation**

ğŸ‘‰ **[ğŸ¤–Try it live ](https://reasoning-quality-analyzer.streamlit.app/) â€” Instant logical error detection in your browser. Powered by Streamlit Cloud.**



---
## âœ… Example
```
ğŸ“„ Ğ¢ĞµĞºÑÑ‚:
ĞŸĞ¾ÑĞ»Ğµ Ñ‚Ğ¾Ğ³Ğ¾ ĞºĞ°Ğº Ğ² Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ñ†ĞµĞ½Ñ‚Ñ€, ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ»Ğ¾ÑÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¾Ğ´Ğ¾Ğ². 
Ğ¡Ğ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾, Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ†ĞµĞ½Ñ‚Ñ€Ğ° Ñ€Ğ°Ğ·Ñ€ÑƒÑˆĞ°ĞµÑ‚ ÑĞµĞ¼ÑŒĞ¸.

ğŸ” ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: Ğ”Ğ (100.00%)

âŒ Ğ¯Ğ²Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸:
  â€¢ Ğ›Ğ¾Ğ¶Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ½Ğ¾-ÑĞ»ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ â€” 95.95%

ğŸ“Š Disagreement: 0.034
```
---

## ğŸ“œ License

MIT

---
