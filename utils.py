# ============================================================
# utils.py â€” Ð¾Ð±Ñ‰Ð¸Ðµ ÐºÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹, ÐºÐ»Ð°ÑÑ RQAJudge, Ð·Ð°Ð³Ñ€ÑƒÐ·Ñ‡Ð¸ÐºÐ¸
# ============================================================

import os
import json
import csv
import torch
from typing import List, Dict, Any
from transformers import AutoTokenizer, AutoModel

# ============================================================
# ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹
# ============================================================

ERROR_TYPES = [
    "false_causality",
    "unsupported_claim",
    "overgeneralization",
    "missing_premise",
    "contradiction",
    "circular_reasoning",
]

ERROR_NAMES_RU = {
    "false_causality": "Ð›Ð¾Ð¶Ð½Ð°Ñ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð½Ð¾-ÑÐ»ÐµÐ´ÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ ÑÐ²ÑÐ·ÑŒ",
    "unsupported_claim": "ÐÐµÐ¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»Ñ‘Ð½Ð½Ð¾Ðµ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ",
    "overgeneralization": "Ð§Ñ€ÐµÐ·Ð¼ÐµÑ€Ð½Ð¾Ðµ Ð¾Ð±Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ",
    "missing_premise": "ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð°Ñ Ð¿Ñ€ÐµÐ´Ð¿Ð¾ÑÑ‹Ð»ÐºÐ°",
    "contradiction": "ÐŸÑ€Ð¾Ñ‚Ð¸Ð²Ð¾Ñ€ÐµÑ‡Ð¸Ðµ",
    "circular_reasoning": "ÐšÑ€ÑƒÐ³Ð¾Ð²Ð¾Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ",
}

ERROR_THRESHOLDS = {
    "false_causality": 0.55,
    "unsupported_claim": 0.55,
    "overgeneralization": 0.60,
    "missing_premise": 0.80,
    "contradiction": 0.60,
    "circular_reasoning": 0.60,
}

CONFIDENCE_HIGH = 0.85
CONFIDENCE_MEDIUM = 0.65

# ============================================================
# ÐšÐ»Ð°ÑÑ RQAJudge (Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¸Ð· Ð²Ð°ÑˆÐµÐ³Ð¾ ÐºÐ¾Ð´Ð°)
# ============================================================

class RQAJudge:
    def __init__(self, model_name="skatzR/RQA-X1.1", device=None):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(self.device)
        self.model.eval()
        cfg = self.model.config
        self.temp_issue = float(cfg.temperature_has_issue)
        self.temp_errors = list(cfg.temperature_errors)

    @torch.no_grad()
    def infer(self, text: str, issue_threshold: float = 0.6, disagreement_threshold: float = 0.4):
        inputs = self.tokenizer(text, truncation=True, max_length=512,
                                padding="max_length", return_tensors="pt").to(self.device)
        outputs = self.model(**inputs)

        # has_issue
        issue_logit = outputs["has_issue_logits"] / self.temp_issue
        issue_prob = torch.sigmoid(issue_logit).item()
        has_issue = issue_prob >= issue_threshold

        # Ð¾ÑˆÐ¸Ð±ÐºÐ¸ (ÑÑ‹Ñ€Ñ‹Ðµ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸)
        raw_error_logits = outputs["errors_logits"][0]
        raw_probs = {}
        for i, logit in enumerate(raw_error_logits):
            calibrated = logit / self.temp_errors[i]
            prob = torch.sigmoid(calibrated).item()
            raw_probs[ERROR_TYPES[i]] = prob

        # disagreement
        p_any_error_raw = 1.0
        for p in raw_probs.values():
            p_any_error_raw *= (1.0 - p)
        p_any_error_raw = 1.0 - p_any_error_raw
        disagreement = abs(issue_prob - p_any_error_raw)

        # HARD-GATING
        error_probs = raw_probs.copy() if has_issue else {k: 0.0 for k in raw_probs}

        # ÑÐ²Ð½Ñ‹Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ (ÐºÑ€Ð¾Ð¼Ðµ missing_premise)
        explicit_errors = []
        for err, prob in error_probs.items():
            if prob >= ERROR_THRESHOLDS[err] and err != "missing_premise":
                explicit_errors.append((err, prob))
        explicit_errors.sort(key=lambda x: x[1], reverse=True)

        # hidden_problem
        hidden_problem = has_issue and not explicit_errors and issue_prob >= 0.6

        # borderline
        borderline = not has_issue and hidden_problem and disagreement >= disagreement_threshold

        # confidence bands
        if issue_prob >= CONFIDENCE_HIGH:
            confidence = "Ð’Ð«Ð¡ÐžÐšÐÐ¯"
        elif issue_prob >= CONFIDENCE_MEDIUM:
            confidence = "Ð¡Ð Ð•Ð”ÐÐ¯Ð¯"
        else:
            confidence = "ÐÐ˜Ð—ÐšÐÐ¯"

        # Ñ‚Ð¾Ð¿â€‘2 Ð¾ÑˆÐ¸Ð±ÐºÐ¸ (Ð´Ð»Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸)
        sorted_all = sorted(error_probs.items(), key=lambda x: x[1], reverse=True)
        top_errors = []
        for err, prob in sorted_all[:2]:
            top_errors.append({
                "type": err,
                "probability": prob,
                "above_threshold": prob >= ERROR_THRESHOLDS[err]
            })

        return {
            "text": text,
            "has_issue": has_issue,
            "issue_probability": issue_prob,
            "confidence": confidence,
            "explicit_errors": explicit_errors,
            "hidden_problem": hidden_problem,
            "borderline": borderline,
            "disagreement": disagreement,
            "top_errors": top_errors,
            "raw_probs": raw_probs
        }

# ============================================================
# Ð—Ð°Ð³Ñ€ÑƒÐ·Ñ‡Ð¸ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð¾Ð² (Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð±Ð°Ð¹Ñ‚Ð¾Ð²Ñ‹Ð¼Ð¸ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°Ð¼Ð¸)
# ============================================================

def load_texts_from_uploaded_file(uploaded_file) -> List[str]:
    """
    Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ñ‹ Ð¸Ð· Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° (Ð¾Ð±ÑŠÐµÐºÑ‚ BytesIO).
    ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ .txt, .csv, .json.
    """
    ext = os.path.splitext(uploaded_file.name)[1].lower()
    content = uploaded_file.read().decode("utf-8")

    if ext == ".txt":
        return [line.strip() for line in content.splitlines() if line.strip()]

    if ext == ".csv":
        import csv
        from io import StringIO
        reader = csv.DictReader(StringIO(content))
        return [row["text"] for row in reader]

    if ext == ".json":
        data = json.loads(content)
        if isinstance(data, list):
            return data
        else:
            raise ValueError("JSON Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÑ‚Ñ€Ð¾Ðº")

    raise ValueError("ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ð°")

# ============================================================
# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð² HTML/Markdown Ð´Ð»Ñ Streamlit
# ============================================================

def format_result_for_streamlit(r: Dict[str, Any]) -> str:
    lines = []
    lines.append("### ðŸ“„ Ð¢ÐµÐºÑÑ‚")
    lines.append(f">{r['text']}")

    prob_percent = r['issue_probability'] * 100
    status = "âœ… ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼ ÐÐ• Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾" if not r['has_issue'] else "âŒ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð°"
    lines.append(f"\n**{status}**  \nÐ’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ: {prob_percent:.2f}% â€” ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {r['confidence']}")

    if r["borderline"]:
        lines.append("âš ï¸ **ÐŸÐ¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð½Ñ‹Ð¹ ÑÐ»ÑƒÑ‡Ð°Ð¹**: Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚")
    if r["hidden_problem"]:
        lines.append("ðŸŸ¡ **Ð¡ÐºÑ€Ñ‹Ñ‚Ð°Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°**: Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹ Ð½ÐµÑÐ²Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´Ð¿Ð¾ÑÑ‹Ð»ÐºÐ¸")

    if r["explicit_errors"]:
        lines.append("\n**âŒ Ð¯Ð²Ð½Ñ‹Ðµ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸:**")
        for name, prob in r["explicit_errors"]:
            lines.append(f"- {ERROR_NAMES_RU[name]} â€” {prob*100:.2f}%")

    below = [e for e in r["top_errors"] if not e["above_threshold"] and e["probability"] > 0.01]
    if below:
        lines.append("\n**ðŸ“‰ Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ (Ð½Ð¸Ð¶Ðµ Ð¿Ð¾Ñ€Ð¾Ð³Ð°):**")
        for e in below:
            name_ru = ERROR_NAMES_RU.get(e["type"], e["type"])
            lines.append(f"- {name_ru} â€” {e['probability']*100:.2f}% (Ð¿Ð¾Ñ€Ð¾Ð³ {ERROR_THRESHOLDS[e['type']]*100:.0f}%)")

    lines.append(f"\n**ðŸ“Š Disagreement:** {r['disagreement']:.3f}")
    return "\n".join(lines)
